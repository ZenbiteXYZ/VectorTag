# üè∑Ô∏è VectorTag: Automatic Image Tagging System

A deep learning system for image tags generation. Uses ResNET-18 backbone.

## üéØ Overview

**VectorTag** automatically tags images with semantic labels (e.g., "building", "food", "person", "nature"). The system:

- **Multi-label classification:** Each image can have multiple tags simultaneously.
- **Interpretable predictions:** Uses Grad-CAM to visualize which image regions influenced each tag.
- **Interactive UI:** Streamlit-based web interface for inference and exploration.
- **Production-ready:** Docker containerization for easy deployment.

### Key Features

- **ResNet-18** backbone pretrained on ImageNet
- **BCEWithLogitsLoss** with class weighting to handle imbalanced datasets
- **Grad-CAM visualization** for model interpretability
- **Data augmentation** (rotation, flips, color jitter)
- **LR Scheduler** with early stopping to prevent overfitting
- **Streamlit UI** for interactive inference
- **Docker deployment** ready

---

## üìä Project Structure

```
VectorTag/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ config.py                 # Central configuration (paths, hyperparams)
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tagged_dataset.py         # PyTorch Dataset class
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ loaders.py                # DataLoader creation with transforms
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ taxonomy.py               # Tag synonyms and hierarchies
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ baseline.py               # ResNet-18 model definition
‚îÇ   ‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ train.py                  # Training loop with auto-plotting
‚îÇ   ‚îú‚îÄ‚îÄ ui/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app.py                    # Main Streamlit app
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ modes/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.py               # Abstract inference mode
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ standard.py           # Standard inference mode
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ components/               # Reusable UI components
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îú‚îÄ‚îÄ gradcam.py                # Grad-CAM heatmap generation
‚îÇ       ‚îî‚îÄ‚îÄ plotting.py               # Training visualization
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ standard/
‚îÇ       ‚îú‚îÄ‚îÄ weights/                  # Saved model weights (.pth)
‚îÇ       ‚îî‚îÄ‚îÄ classes/                  # Class definitions (.json)
‚îú‚îÄ‚îÄ assets/
‚îÇ   ‚îú‚îÄ‚îÄ exp_00X_*.png                 # Training curves from experiments
‚îÇ   ‚îî‚îÄ‚îÄ comparison_*.png              # Grad-CAM comparisons
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ raw/
‚îÇ       ‚îî‚îÄ‚îÄ various_tagged_images/    # Dataset images + metadata.csv
‚îú‚îÄ‚îÄ experiments.md                    # Detailed experiment logs
‚îú‚îÄ‚îÄ requirements.txt                  # Python dependencies
‚îú‚îÄ‚îÄ Dockerfile                        # Container definition
‚îî‚îÄ‚îÄ README.md                         # This file
```

---

## üöÄ Quick Start

### 1. Setup Environment

```bash
# Clone repository (choose one method below)

# HTTPS
git clone https://github.com/ZenbiteXYZ/VectorTag.git

# Or SSH
git clone git@github.com:ZenbiteXYZ/VectorTag.git

# Navigate to directory
cd VectorTag

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Download Dataset

Download the [Kaggle Various Tagged Images dataset](https://www.kaggle.com/datasets/greg115/various-tagged-images) and extract to:

```
data/raw/various_tagged_images/
‚îú‚îÄ‚îÄ metadata.csv
‚îú‚îÄ‚îÄ image_1.jpg
‚îú‚îÄ‚îÄ image_2.jpg
‚îî‚îÄ‚îÄ ...
```

### 3. Launch UI

```bash
streamlit run src/ui/app.py
```

Then navigate to `http://localhost:8501` in your browser.

> **Note:** Pre-trained model weights are already included in `models/standard/weights/`. For retraining with custom settings, see [Training Your Own Model](#-training-your-own-model) section below.

---

## üìà Experimental Results

### Experiment 005: **BCEWithLogitsLoss + Class Weights** ‚≠ê Current Best

**Configuration:**
- **Loss:** BCEWithLogitsLoss with `pos_weight` (balanced classes)
- **Data:** 200K samples, Top-150 tags, stratified split
- **Training:** 12 epochs, LR Scheduler, Weight Decay=1e-5

**Results:**

| Epoch | Train Loss | Val Loss | Notes |
|-------|------------|----------|-------|
| 1     | 0.2569     | 0.2028   | High loss due to pos_weight |
| 2     | 0.2107     | 0.1925   | Quick descent |
| 7     | 0.1726     | **0.1835** | **Best validation point** |
| 12    | 0.1372     | 0.1932   | Training continues |

![Learning Curve Exp 005](assets/exp_005_weighted.png)

**Key Insights:**
1. ‚úÖ **Sharp Grad-CAM:** Model focuses on relevant image regions without noise.
2. ‚úÖ **High Confidence:** Predictions reach 70%+ for confident tags.
3. ‚ö†Ô∏è **Overfitting starts:** After epoch 7, validation loss increases (expected with imbalanced data).
4. ‚úÖ **Best generalization:** Compared to other loss functions (Focal Loss performed worse).

### Visual Analysis

**Building Tag (Grad-CAM Comparison):**
- **Exp 002 (BCE):** Clear boundary, but low confidence (37%).
- **Exp 004 (Focal):** Blurry boundary, more noise (43% confidence).
- **Exp 005 (Weighted BCE):** ‚≠ê **Best:** Sharp boundary, high confidence (70%), captures building outline without sky.

![GradCAM Building Comparison](assets/comparison_building_2x4x5.png)

**Food Tag (Grad-CAM Comparison):**

![GradCAM Food Comparison](assets/comparison_food_2x4x5.png)

---

## üîß Configuration

Edit `src/core/config.py` to customize:

```python
# Model
BATCH_SIZE = 16              # Reduce for high-res images
LEARNING_RATE = 1e-4         # Baseline learning rate
EPOCHS = 12                  # Total epochs
WEIGHT_DECAY = 1e-5          # L2 regularization

# Data
TOP_K = 150                  # Use top-150 most frequent tags
MAX_SAMPLES = 200_000        # Limit dataset size (for speed)
```

---

## üê≥ Docker Deployment

```bash
# Build image
docker build -t vectortag-ui .

# Run container
docker run --rm -p 8501:8501 \
  -v $(pwd)/models:/app/models \
  vectortag-ui
```

Access UI at `http://localhost:8501`

---

## üéì Training Your Own Model

To train or retrain the model with custom settings:

```bash
python src/scripts/train.py
```

**What happens:**
- Loads data with augmentation (crop, flip, rotation, color jitter)
- Computes class weights for imbalanced tags
- Trains ResNet-18 for N epochs
- Saves best model to `models/standard/weights/`
- Auto-generates learning curve plot

**All settings are configurable in `src/core/config.py`:**
- `TOP_K`: Number of tags (default: 150)
- `BATCH_SIZE`: Batch size (default: 32)
- `EPOCHS`: Training epochs (default: 12)
- `LEARNING_RATE`: Base LR (default: 1e-4)
- `WEIGHT_DECAY`: Regularization (default: 1e-5)

---

## üìö Key Technical Components

### Data Processing (`src/data/`)

- **TaggedImagesDataset:** Multi-label dataset with tag synonyms and hierarchies.
- **Stratified split:** Ensures rare classes are equally distributed in train/val.
- **Smart subsampling:** Weights samples by class rarity for balanced mini-batches.

### Model Architecture (`src/models/baseline.py`)

```python
ResNet-18 (ImageNet pretrained)
    ‚Üì
Feature Extractor ‚Üí 512D
    ‚Üì
Linear(512 ‚Üí 256)
    ‚Üì
  ReLU()
    ‚Üì
Dropout(0.4)
    ‚Üì
Linear(256 ‚Üí num_classes)
    ‚Üì
BCEWithLogitsLoss (per-class)
```

### Grad-CAM Visualization (`src/utils/gradcam.py`)

- Computes class activation maps using gradients.

### Training Pipeline (`src/scripts/train.py`)

1. **Class weight computation:** `pos_weight = (N_neg / N_pos)` clamped to [1.0, 20.0]
2. **LR Scheduler:** ReduceLROnPlateau reduces learning rate on validation plateau
3. **Early stopping:** Saves only best model based on validation loss
4. **Auto-plotting:** Generates learning curve after training

---

## üîÆ Future Improvements

- [ ] **Dynamic tag addition:** Add new tags without full model retraining
- [ ] **Vision Transformer (ViT):** Replace ResNet-18 with ViT for better accuracy

---

## üìñ Experiment Log

Detailed experiments are documented in [experiments.md](experiments.md):

- **Exp 001:** Baseline (Overfitting issue discovered)
- **Exp 002:** Synonyms + Dropout + Augmentation (Overfitting solved)
- **Exp 003:** LR Scheduler + Weight Decay (Better convergence)
- **Exp 004:** FocalLoss (Poor Grad-CAM quality)
- **Exp 005:** **Weighted BCE** ‚≠ê (Current best)

---

## üì¶ Dependencies

- **torch, torchvision:** Deep learning
- **pillow, pandas:** Image & data processing
- **scikit-learn:** Stratified split
- **streamlit:** Web UI
- **pydantic:** Configuration management

---

## ü§ù Contributing

Contributions welcome! Areas of interest:

- Better loss functions for imbalanced multi-label classification
- Improved data augmentation strategies
- Alternative backbone architectures
- Performance optimizations

---

## üìÑ License

See [LICENSE](LICENSE) file.

---
