# Experiment Log

## Experiment 001: Baseline
**Дата:** 24.12.2025
**Статус:** Overfitting

### Configuration
* **Dataset:** Kaggle Various Tagged Images
* **Samples:** 10,000 (80/20)
* **Classes:** Top-30 (Raw tags, no synonyms)
* **Model:** ResNet-18 (Pretrained)
* **Augmentation:** None (Resize + Normalize only)

### Results
| Epoch | Train Loss | Val Loss | Комментарий |
|-------|------------|----------|-------------|
| 1     | 0.1753     | 0.1070   | Нормальный старт |
| 2     | 0.0983     | **0.0984** | Лучшая точка |
| 3     | 0.0761     | 0.0989   | Val Loss начал расти |
| 4     | 0.0558     | 0.1050   | Переобучение усиливается |
| 5     | 0.0395     | 0.1092   | Сильное переобучение |

### Conclusions
1. Модель быстро выучивает тренировочную выборку (Loss падает до 0.04).
2. Валидация деградирует после 2-й эпохи.
3. **Проблема:** Шумные теги (human vs person) и отсутствие регуляризации.

---

## Experiment 002: Synonyms + Dropout + Augmentation
**Дата:** 25.12.2025
**Статус:** Success

### Changes
1. **Data:**
   - Внедрен словарь синонимов (`human` -> `person`) и иерархия (`man` -> `person`).
   - Увеличен размер выборки: **50,000** сэмплов (80/20).
2. **Model:** Добавлен слой `Dropout(p=0.4)` перед классификатором.
3. **Training:**
   - Augmentation: RandomCrop, RandomFlip, RandomRotation, ColorJitter
   - Сохранение только лучшей модели (`early_stopping`).

### Results
| Epoch | Train Loss | Val Loss | Комментарий |
|-------|------------|----------|-------------|
| 1     | 0.1325     | 0.0960   | Стабильный старт, Val Loss ниже чем в первой Эпохе |
| 2     | 0.1007     | **0.0912** | Лучшая точка (Best Val) |
| 3     | 0.0935     | 0.0935   | Train и Val одинаковые (нет переобучения!) |
| 4     | 0.0881     | 0.0914   | Стабильное плато |
| 5     | 0.0839     | 0.0959   | Небольшой рост Val, но в пределах нормы |

### Conclusions
1. **Переобучение побеждено:** Разрыв между Train и Val минимален (~1%).
2. **Качество выросло:** Val Loss упал с 0.0984 (Exp 001) до 0.0912.
3. **Аугментация работает:** Модель учится медленнее, но качественнее.
4. **Следующие шаги:** Можно попробовать увеличить число эпох (до 10-15), размер выборки (до 100,000), увеличить и добавить LR Scheduler (уменьшать learning rate, когда loss выходит на плато).

---

## Experiment 003: LR Scheduler + Weight Decay + Increased Dataset
**Дата:** 25.12.2025
**Статус:** Success

### Changes
1. **Data:**
   - Увеличен размер выборки: **100,000** сэмплов (80/20).
2. **Model:** Dropout(p=0.4) перед классификатором.
3. **Training:**
   - **Регуляризация:** Weight Decay = 1e-4.
   - **LR Scheduler:** ReduceLROnPlateau (factor=0.1, patience=2).
   - **Epochs:** 8 (вместо 5).

### Results
| Epoch | Train Loss | Val Loss | LR | Комментарий |
|-------|------------|----------|------------|-------------|
| 1     | 0.0832     | 0.0670   | 1e-04 | Стабильный старт |
| 2     | 0.0679     | 0.0646   | 1e-04 | Близко к лучшему |
| 3     | 0.0666     | 0.0651   | 1e-04 | Плато начинается |
| 4     | 0.0660     | 0.0647   | 1e-04 | Топчется на месте |
| 5     | 0.0656     | 0.0659   | 1e-04 | Val растет → Scheduler активируется |
| 6     | 0.0602     | 0.0622   | **1e-05** | LR снижен |
| 7     | 0.0582     | **0.0617** | 1e-05 | **Новый рекорд Val Loss** |
| 8     | 0.0571     | 0.0638   | 1e-05 | Небольшой откат, но в пределах нормы |

### Conclusions
1. **LR Scheduler сработал отлично:** На 6-й эпохе скорость обучения упала в 10 раз (с `1e-4` до `1e-5`), что позволило модели "дожать" Loss и пробить плато.
2. **Лучший результат:** Val Loss **0.0617** — это на **37% лучше**, чем в Exp 001 (0.0984), и на **32% лучше**, чем в Exp 002 (0.0912).
3. **Стабильность:** Разрыв между Train и Val остается минимальным (~1%), что говорит об отсутствии переобучения.
4. **Weight Decay работает:** Без него Val Loss увеличивался больше.
5. **Следующие шаги:**
   - Увеличить количество тегов (100-150) и сэмплов (200,000),
   - Увеличить количество эпох (10-12)
